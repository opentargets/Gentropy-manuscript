{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "The aim of this notebook is to collect the information about the credible set lead variants.\n",
    "This includes:\n",
    "\n",
    "- Addition of Major population sample size and size of cases/controls from studyIndex,\n",
    "- Addition of most severe consequences and consequence score derived from VEP annotations from variantIndex\n",
    "- Calculation of MAF (Minor Allele Frequency) for lead variants\n",
    "- Calculation of Variance Explained by lead variant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Data extraction and loading\n",
    "\n",
    "Data for this analysis has to be downloaded from 3 datasets available by FTP:\n",
    "\n",
    "- credible_set\n",
    "- variant\n",
    "- study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Ensure proper java version < 11\n",
    "!java -version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "!rsync -rpltvz --delete rsync.ebi.ac.uk::pub/databases/opentargets/platform/25.03/output/credible_set ../../data/.\n",
    "!rsync -rpltvz --delete rsync.ebi.ac.uk::pub/databases/opentargets/platform/25.03/output/study ../../data/.\n",
    "!rsync -rpltvz --delete rsync.ebi.ac.uk::pub/databases/opentargets/platform/25.03/output/variant ../../data/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data with gentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gentropy.common.session import Session\n",
    "from gentropy.dataset.study_index import StudyIndex\n",
    "from gentropy.dataset.study_locus import StudyLocus\n",
    "from gentropy.dataset.variant_index import VariantIndex\n",
    "from pyspark.sql import Column, Window\n",
    "from pyspark.sql import functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "session = Session(extended_spark_conf={\"spark.driver.memory\": \"40G\"})\n",
    "variant_index_path = \"../../data/variant\"\n",
    "study_index_path = \"../../data/study\"\n",
    "credible_set_path = \"../../data/credible_set\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "session.spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = VariantIndex.from_parquet(session, variant_index_path)\n",
    "si = StudyIndex.from_parquet(session, study_index_path)\n",
    "cs = StudyLocus.from_parquet(session, credible_set_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "vi.df.show(n=1)\n",
    "si.df.show(n=1)\n",
    "cs.df.show(n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAF dataset\n",
    "\n",
    "The dataset below contains lead variants from credible sets contains:\n",
    "\n",
    "- maf\n",
    "- major population used to calculate maf\n",
    "- trait infromation derived from `traitFromSourceMappedIds` or `geneId` fields depending on the studyType found from study index\n",
    "- allelic frequencies derived from variant index (gnomAD) for major population found in `ldPopulationStructure` in study index\n",
    "- vep score\n",
    "- information about the cases and controls counts from study index\n",
    "- variant association statistics from study locus\n",
    "- study type\n",
    "\n",
    "Code below collects all required fields required to perform analysis on MAF and variant effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_population_in_study(ld_col: Column, default_major_pop: str = \"nfe\") -> Column:\n",
    "    \"\"\"Extract the major population from the study ld population structure.\n",
    "\n",
    "    Args:\n",
    "        ld_col (Column): ld population structure field  array<struct<ldPopulation: string, relativeSampleSize: double>>\n",
    "        default_major_pop (str, optional): population to use as default, when no population was reported. Defaults to \"nfe\".\n",
    "\n",
    "    Returns:\n",
    "        Column: ld_col struct\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def reduce_pops(pop1: Column, pop2: Column) -> Column:\n",
    "        \"\"\"Reduce two populations based on relative sample size.\n",
    "\n",
    "        This function takes 2 populations and report one of them based on following conditions:\n",
    "        * Use pop with bigger relativeSampleSize\n",
    "        * In case of a tie, the default_major_pop is preferred,\n",
    "        * In case of tie and no default_major_pop in pop1 and pop2, use pop1.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            f.when(pop1.getField(\"relativeSampleSize\") > pop2.getField(\"relativeSampleSize\"), pop1)\n",
    "            .when(pop1.getField(\"relativeSampleSize\") < pop2.getField(\"relativeSampleSize\"), pop2)\n",
    "            .when(\n",
    "                (\n",
    "                    (pop1.getField(\"relativeSampleSize\") == pop2.getField(\"relativeSampleSize\"))\n",
    "                    & (pop1.getField(\"ldPopulation\") == f.lit(default_major_pop))\n",
    "                ),\n",
    "                pop1,\n",
    "            )\n",
    "            .when(\n",
    "                (\n",
    "                    (pop1.getField(\"relativeSampleSize\") == pop2.getField(\"relativeSampleSize\"))\n",
    "                    & (pop2.getField(\"ldPopulation\") == f.lit(default_major_pop))\n",
    "                ),\n",
    "                pop2,\n",
    "            )\n",
    "            .otherwise(pop1)\n",
    "        )\n",
    "\n",
    "    fallback = f.struct(f.lit(default_major_pop).alias(\"ldPopulation\"), f.lit(0.0).alias(\"relativeSampleSize\"))\n",
    "\n",
    "    return f.when(\n",
    "        f.size(ld_col) > 0,\n",
    "        f.reduce(\n",
    "            ld_col,\n",
    "            fallback,\n",
    "            reduce_pops,\n",
    "        ),\n",
    "    ).otherwise(fallback)\n",
    "\n",
    "\n",
    "def vep_variant_effect(c: Column) -> Column:\n",
    "    \"\"\"Extract VEP variant effect.\"\"\"\n",
    "\n",
    "    def extract_fields(ve: Column) -> Column:\n",
    "        return f.struct(\n",
    "            ve.getField(\"assessment\").alias(\"assessment\"),\n",
    "            ve.getField(\"normalisedScore\").alias(\"normalisedScore\"),\n",
    "            ve.getField(\"targetId\").alias(\"targetId\"),\n",
    "        )\n",
    "\n",
    "    return f.transform(f.filter(c, lambda ve: ve.getField(\"method\") == f.lit(\"VEP\")), extract_fields).getItem(0)\n",
    "\n",
    "\n",
    "def major_population_allele_freq(major_pop: Column, allele_freq: Column) -> Column:\n",
    "    \"\"\"Extract major population from variant.alleleFrequencies.\"\"\"\n",
    "    return f.filter(\n",
    "        allele_freq,\n",
    "        lambda freq: f.replace(freq.getField(\"populationName\"), f.lit(\"_adj\"), f.lit(\"\"))\n",
    "        == major_pop.getField(\"ldPopulation\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def maf(variant_freq: Column) -> Column:\n",
    "    \"\"\"Calculate Minor Allele Frequency from variant frequency.\"\"\"\n",
    "    return (\n",
    "        f.when(\n",
    "            ((f.size(variant_freq) == 1) & (variant_freq.getItem(0).getField(\"alleleFrequency\") > 0.5)),\n",
    "            f.lit(1.0) - variant_freq.getItem(0).getField(\"alleleFrequency\"),\n",
    "        )\n",
    "        .when(\n",
    "            ((f.size(variant_freq) == 1) & (variant_freq.getItem(0).getField(\"alleleFrequency\") <= 0.5)),\n",
    "            variant_freq.getItem(0).getField(\"alleleFrequency\"),\n",
    "        )\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_pip_from_locus(variant_col: Column, locus: Column) -> Column:\n",
    "    \"\"\"Extract Posterior propability from variant from locus.\n",
    "\n",
    "    In the case the lead variant is not present in the locus, None is returned.\n",
    "    \"\"\"\n",
    "    lead_variant_stats = f.filter(locus, lambda v: v.getField(\"variantId\") == variant_col)\n",
    "    return (\n",
    "        f.when(\n",
    "            f.size(lead_variant_stats) == 1,\n",
    "            lead_variant_stats.getItem(0).getField(\"posteriorProbability\"),\n",
    "        )\n",
    "        .otherwise(None)\n",
    "        .alias(\"posteriorProbability\")\n",
    "    )\n",
    "\n",
    "\n",
    "def create_maf_dataset(si: StudyIndex, cs: StudyLocus, vi: VariantIndex):\n",
    "    \"\"\"Create MAF dataset from StudyIndex, StudyLocus and VariantIndex.\n",
    "\n",
    "    Args:\n",
    "        si (StudyIndex): StudyIndex object\n",
    "        cs (StudyLocus): StudyLocus object\n",
    "        vi (VariantIndex): VariantIndex object\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: MAF dataset\n",
    "\n",
    "    \"\"\"\n",
    "    _cs = cs.df.select(\n",
    "        f.col(\"studyId\"),\n",
    "        f.col(\"studyLocusId\"),\n",
    "        f.col(\"variantId\"),\n",
    "        f.col(\"beta\"),\n",
    "        f.col(\"zScore\"),\n",
    "        f.col(\"pValueMantissa\"),\n",
    "        f.col(\"pValueExponent\"),\n",
    "        f.col(\"standardError\"),\n",
    "        f.col(\"finemappingMethod\"),\n",
    "        f.col(\"studyType\"),\n",
    "        f.size(\"locus\").alias(\"credibleSetSize\"),\n",
    "        f.col(\"isTransQtl\"),\n",
    "        extract_pip_from_locus(f.col(\"variantId\"), f.col(\"locus\")),\n",
    "    )\n",
    "    _si = si.df.select(\n",
    "        f.col(\"studyId\"),\n",
    "        f.col(\"nSamples\"),\n",
    "        f.col(\"nControls\"),\n",
    "        f.col(\"nCases\"),\n",
    "        f.col(\"geneId\"),  # for molqtl traits\n",
    "        f.col(\"traitFromSourceMappedIds\"),\n",
    "        major_population_in_study(f.col(\"ldPopulationStructure\"), \"nfe\").alias(\"majorPopulation\"),\n",
    "    )\n",
    "\n",
    "    _vi = vi.df.select(\n",
    "        f.col(\"variantId\"),\n",
    "        f.col(\"allelefrequencies\"),\n",
    "        vep_variant_effect(\"variantEffect\").alias(\"vepEffect\"),\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        _cs.join(_si, how=\"left\", on=\"studyId\")\n",
    "        .join(_vi, how=\"left\", on=\"variantId\")\n",
    "        .select(\n",
    "            \"*\",\n",
    "            major_population_allele_freq(\n",
    "                f.col(\"majorPopulation\"),\n",
    "                f.col(\"alleleFrequencies\"),\n",
    "            ).alias(\"majorPopulationAF\"),\n",
    "        )\n",
    "        .select(\n",
    "            \"*\",\n",
    "            maf(f.col(\"majorPopulationAf\")).alias(\"majorPopulationMAF\"),\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAF dataset consists of specific fields from credible sets, study index and variant index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_maf = create_maf_dataset(si, cs, vi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of lead variants is 2622098\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dataset_maf.write.mode(\"overwrite\").parquet(\"../../data/lead-maf-vep\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systematic finemapping\n",
    "\n",
    "The goal is to see how many lead variants from credible sets had correctly calculated MAF\n",
    "\n",
    "There would be cases where:\n",
    "\n",
    "1. majorPopulationMAF == 0.0 in case the gnomAD allelic frequencies for population matching majorPopulation defined in study did not capture the variant\n",
    "2. majorPopulationMAF not inferred correctly when variant was not found in gnomAD, so allelic frequencies could not be\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_maf = session.spark.read.parquet(\"../../data/lead-maf-vep\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many lead variants have maf calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = StudyLocus.from_parquet(session, credible_set_path).df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cs.count() == dataset_maf.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "if cs.count() == dataset_maf.count():\n",
    "    w = Window().partitionBy()\n",
    "    print(\"Counts are equal\")\n",
    "    print(\"Estimating the MAF distribution\")\n",
    "    dataset_maf.select(\n",
    "        f.col(\"majorPopulationMAF\"),\n",
    "        f.col(\"variantId\"),\n",
    "        f.when(f.col(\"majorPopulationMAF\").isNull(), f.lit(\"Unable to infer MAF\"))\n",
    "        .when(f.col(\"majorPopulationMAF\") == 0.0, f.lit(\"MAF eq 0.0\"))\n",
    "        .otherwise(\"able to infer MAF\")\n",
    "        .alias(\"majorPopulationMAFInterenceGroup\"),\n",
    "    ).groupBy(\"majorPopulationMAFInterenceGroup\").agg(\n",
    "        f.count(\"*\").alias(\"count\"),\n",
    "        f.collect_list(\"variantId\").alias(\"majorPopulationMAFList\"),\n",
    "    ).withColumn(\"total\", f.sum(f.col(\"count\")).over(w)).withColumn(\n",
    "        \"%\", f.round(f.col(\"count\") / f.col(\"total\") * 100, 2)\n",
    "    ).withColumn(\"majorPopulationMAFList\", f.slice(f.col(\"majorPopulationMAFList\"), 1, 3)).show(truncate=False)\n",
    "else:\n",
    "    print(\"Counts are not equal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "vi.df.filter(f.col(\"variantId\") == \"10_12914618_G_A\").show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
