{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "The aim of this notebook is to collect the information about the credible set lead variants.\n",
    "This includes:\n",
    "\n",
    "- Addition of Major population sample size and size of cases/controls from studyIndex,\n",
    "- Addition of most severe consequences and consequence score derived from VEP annotations from variantIndex\n",
    "- Calculation of MAF (Minor Allele Frequency) for lead variants\n",
    "- Calculation of Variance Explained by lead variant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Data extraction and loading\n",
    "\n",
    "Data for this analysis has to be downloaded from 3 datasets available by FTP:\n",
    "\n",
    "- credible_set\n",
    "- variant\n",
    "- study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"17.0.14\" 2025-01-21\n",
      "OpenJDK Runtime Environment Temurin-17.0.14+7 (build 17.0.14+7)\n",
      "OpenJDK 64-Bit Server VM Temurin-17.0.14+7 (build 17.0.14+7, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "# Ensure proper java version < 11\n",
    "!java -version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receiving incremental file list\n",
      "\n",
      "sent 29 bytes  received 1.770 bytes  1.199,33 bytes/sec\n",
      "total size is 2.371.305.976  speedup is 1.318.124,50\n",
      "receiving incremental file list\n",
      "\n",
      "sent 29 bytes  received 158 bytes  374,00 bytes/sec\n",
      "total size is 92.431.236  speedup is 494.284,68\n",
      "receiving incremental file list\n",
      "\n",
      "sent 29 bytes  received 1.771 bytes  3.600,00 bytes/sec\n",
      "total size is 3.060.963.047  speedup is 1.700.535,03\n"
     ]
    }
   ],
   "source": [
    "!rsync -rpltvz --delete rsync.ebi.ac.uk::pub/databases/opentargets/platform/25.03/output/credible_set ../../data/.\n",
    "!rsync -rpltvz --delete rsync.ebi.ac.uk::pub/databases/opentargets/platform/25.03/output/study ../../data/.\n",
    "!rsync -rpltvz --delete rsync.ebi.ac.uk::pub/databases/opentargets/platform/25.03/output/variant ../../data/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data with gentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"f6442101-efed-47d4-a821-c8dd291f5f99\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"f6442101-efed-47d4-a821-c8dd291f5f99\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"f6442101-efed-47d4-a821-c8dd291f5f99\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gentropy.common.session import Session\n",
    "from gentropy.dataset.study_index import StudyIndex\n",
    "from gentropy.dataset.study_locus import StudyLocus\n",
    "from gentropy.dataset.variant_index import VariantIndex\n",
    "from pyspark.sql import Column\n",
    "from pyspark.sql import functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/17 08:46:03 WARN Utils: Your hostname, mindos resolves to a loopback address: 127.0.1.1; using 192.168.0.100 instead (on interface eno1)\n",
      "25/04/17 08:46:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/17 08:46:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "session = Session(extended_spark_conf={\"spark.driver.memory\": \"40G\"})\n",
    "variant_index_path = \"../../data/variant\"\n",
    "study_index_path = \"../../data/study\"\n",
    "credible_set_path = \"../../data/credible_set\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.100:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>gentropy</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7d62cae21bd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = VariantIndex.from_parquet(session, variant_index_path)\n",
    "si = StudyIndex.from_parquet(session, study_index_path)\n",
    "cs = StudyLocus.from_parquet(session, credible_set_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+---------------+---------------+--------------------+-----------------------+----------------------+-----------+-----------------+--------------------+--------------------+--------------------+\n",
      "|       variantId|chromosome| position|referenceAllele|alternateAllele|       variantEffect|mostSevereConsequenceId|transcriptConsequences|      rsIds|           hgvsId|   alleleFrequencies|             dbXrefs|  variantDescription|\n",
      "+----------------+----------+---------+---------------+---------------+--------------------+-----------------------+----------------------+-----------+-----------------+--------------------+--------------------+--------------------+\n",
      "|10_104021953_A_G|        10|104021953|              A|              G|[{VEP, intron_var...|             SO_0001627|  [{[SO_0001632], N...|[rs4918077]|10:g.104021953A>G|[{sas_adj, 0.4902...|[{rs4918077, ense...|Intron variant ov...|\n",
      "+----------------+----------+---------+---------------+---------------+--------------------+-----------------------+----------------------+-----------+-----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/17 08:46:09 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------+--------------------+------------------------+-------------+------+---------------------+-----------+--------+----------------+----------------------+---------------+------------------+----------------------------------+--------------------+--------------------+------+---------+--------+---------+---------------------+-------------------+------------------+---------------+-------------+--------------------+-----------+---------+---------------+\n",
      "|             studyId|  projectId|studyType|     traitFromSource|traitFromSourceMappedIds|   diseaseIds|geneId|biosampleFromSourceId|biosampleId|pubmedId|publicationTitle|publicationFirstAuthor|publicationDate|publicationJournal|backgroundTraitFromSourceMappedIds|backgroundDiseaseIds|   initialSampleSize|nCases|nControls|nSamples|  cohorts|ldPopulationStructure|   discoverySamples|replicationSamples|qualityControls|analysisFlags|summarystatsLocation|hasSumstats|condition|sumstatQCValues|\n",
      "+--------------------+-----------+---------+--------------------+------------------------+-------------+------+---------------------+-----------+--------+----------------+----------------------+---------------+------------------+----------------------------------+--------------------+--------------------+------+---------+--------+---------+---------------------+-------------------+------------------+---------------+-------------+--------------------+-----------+---------+---------------+\n",
      "|FINNGEN_R12_AUTOI...|FINNGEN_R12|     gwas|Autoimmune hypert...|           [EFO_0004237]|[EFO_0004237]|  NULL|                 NULL|       NULL|    NULL|            NULL|                  NULL|           NULL|              NULL|                              NULL|                  []|500,348 (282,064 ...|  2469|   370637|  373106|[FinnGen]|         [{fin, 1.0}]|[{500348, Finnish}]|              NULL|             []|           []|gs://finngen-publ...|       true|     NULL|           NULL|\n",
      "+--------------------+-----------+---------+--------------------+------------------------+-------------+------+---------------------+-----------+--------+----------------+----------------------+---------------+------------------+----------------------------------+--------------------+--------------------+------+---------+--------+---------+---------------------+-------------------+------------------+---------------+-------------+--------------------+-----------+---------+---------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------+---------+---------------+----------+--------+------+------------+-------+------+--------------+--------------+-------------------------------+-------------+-------------------+--------------------+-----------------+----------------+------------------+------------+-----------+----------+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "|        studyLocusId|studyType|      variantId|chromosome|position|region|     studyId|   beta|zScore|pValueMantissa|pValueExponent|effectAlleleFrequencyFromSource|standardError|subStudyDescription|     qualityControls|finemappingMethod|credibleSetIndex|credibleSetlog10BF|purityMeanR2|purityMinR2|locusStart|locusEnd|sampleSize|               ldSet|               locus|          confidence|isTransQtl|\n",
      "+--------------------+---------+---------------+----------+--------+------+------------+-------+------+--------------+--------------+-------------------------------+-------------+-------------------+--------------------+-----------------+----------------+------------------+------------+-----------+----------+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "|031afcc3416e65bef...|     gwas|17_38467428_G_T|        17|38467428|  NULL|GCST90430047|30.8091|  NULL|         7.545|            -9|                     0.00105712|      5.32895|               NULL|[Variant not foun...|             PICS|            NULL|              NULL|        NULL|       NULL|      NULL|    NULL|      NULL|[{17_38467428_G_T...|[{true, true, NUL...|PICS fine-mapped ...|      NULL|\n",
      "+--------------------+---------+---------------+----------+--------+------+------------+-------+------+--------------+--------------+-------------------------------+-------------+-------------------+--------------------+-----------------+----------------+------------------+------------+-----------+----------+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vi.df.show(n=1)\n",
    "si.df.show(n=1)\n",
    "cs.df.show(n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAF dataset\n",
    "\n",
    "The dataset below contains lead variants from credible sets contains:\n",
    "\n",
    "- maf\n",
    "- major population used to calculate maf\n",
    "- trait infromation derived from `traitFromSourceMappedIds` or `geneId` fields depending on the studyType found from study index\n",
    "- allelic frequencies derived from variant index (gnomAD) for major population found in `ldPopulationStructure` in study index\n",
    "- vep score\n",
    "- information about the cases and controls counts from study index\n",
    "- variant association statistics from study locus\n",
    "- study type\n",
    "\n",
    "Code below collects all required fields required to perform analysis on MAF and variant effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_population_in_study(ld_col: Column, default_major_pop: str = \"nfe\") -> Column:\n",
    "    \"\"\"Extract the major population from the study ld population structure.\n",
    "\n",
    "    Args:\n",
    "        ld_col (Column): ld population structure field  array<struct<ldPopulation: string, relativeSampleSize: double>>\n",
    "        default_major_pop (str, optional): population to use as default, when no population was reported. Defaults to \"nfe\".\n",
    "\n",
    "    Returns:\n",
    "        Column: ld_col struct\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def reduce_pops(pop1: Column, pop2: Column) -> Column:\n",
    "        \"\"\"Reduce two populations based on relative sample size.\n",
    "\n",
    "        This function takes 2 populations and report one of them based on following conditions:\n",
    "        * Use pop with bigger relativeSampleSize\n",
    "        * In case of a tie, the default_major_pop is preferred,\n",
    "        * In case of tie and no default_major_pop in pop1 and pop2, use pop1.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            f.when(pop1.getField(\"relativeSampleSize\") > pop2.getField(\"relativeSampleSize\"), pop1)\n",
    "            .when(pop1.getField(\"relativeSampleSize\") < pop2.getField(\"relativeSampleSize\"), pop2)\n",
    "            .when(\n",
    "                (\n",
    "                    (pop1.getField(\"relativeSampleSize\") == pop2.getField(\"relativeSampleSize\"))\n",
    "                    & (pop1.getField(\"ldPopulation\") == f.lit(default_major_pop))\n",
    "                ),\n",
    "                pop1,\n",
    "            )\n",
    "            .when(\n",
    "                (\n",
    "                    (pop1.getField(\"relativeSampleSize\") == pop2.getField(\"relativeSampleSize\"))\n",
    "                    & (pop2.getField(\"ldPopulation\") == f.lit(default_major_pop))\n",
    "                ),\n",
    "                pop2,\n",
    "            )\n",
    "            .otherwise(pop1)\n",
    "        )\n",
    "\n",
    "    fallback = f.struct(f.lit(default_major_pop).alias(\"ldPopulation\"), f.lit(0.0).alias(\"relativeSampleSize\"))\n",
    "\n",
    "    return f.when(\n",
    "        f.size(ld_col) > 0,\n",
    "        f.reduce(\n",
    "            ld_col,\n",
    "            fallback,\n",
    "            reduce_pops,\n",
    "        ),\n",
    "    ).otherwise(fallback)\n",
    "\n",
    "\n",
    "def vep_variant_effect(c: Column) -> Column:\n",
    "    \"\"\"Extract VEP variant effect.\"\"\"\n",
    "\n",
    "    def extract_fields(ve: Column) -> Column:\n",
    "        return f.struct(\n",
    "            ve.getField(\"assessment\").alias(\"assessment\"),\n",
    "            ve.getField(\"normalisedScore\").alias(\"normalisedScore\"),\n",
    "            ve.getField(\"targetId\").alias(\"targetId\"),\n",
    "        )\n",
    "\n",
    "    return f.transform(f.filter(c, lambda ve: ve.getField(\"method\") == f.lit(\"VEP\")), extract_fields).getItem(0)\n",
    "\n",
    "\n",
    "def major_population_allele_freq(major_pop: Column, allele_freq: Column) -> Column:\n",
    "    \"\"\"Extract major population from variant.alleleFrequencies.\"\"\"\n",
    "    return f.filter(\n",
    "        allele_freq,\n",
    "        lambda freq: f.replace(freq.getField(\"populationName\"), f.lit(\"_adj\"), f.lit(\"\"))\n",
    "        == major_pop.getField(\"ldPopulation\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def maf(variant_freq: Column) -> Column:\n",
    "    \"\"\"Calculate Minor Allele Frequency from variant frequency.\"\"\"\n",
    "    return (\n",
    "        f.when(\n",
    "            ((f.size(variant_freq) == 1) & (variant_freq.getItem(0).getField(\"alleleFrequency\") > 0.5)),\n",
    "            f.lit(1.0) - variant_freq.getItem(0).getField(\"alleleFrequency\"),\n",
    "        )\n",
    "        .when(\n",
    "            ((f.size(variant_freq) == 1) & (variant_freq.getItem(0).getField(\"alleleFrequency\") <= 0.5)),\n",
    "            variant_freq.getItem(0).getField(\"alleleFrequency\"),\n",
    "        )\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_pip_from_locus(variant_col: Column, locus: Column) -> Column:\n",
    "    \"\"\"Extract Posterior propability from variant from locus.\n",
    "\n",
    "    In the case the lead variant is not present in the locus, None is returned.\n",
    "    \"\"\"\n",
    "    lead_variant_stats = f.filter(locus, lambda v: v.getField(\"variantId\") == variant_col)\n",
    "    return (\n",
    "        f.when(\n",
    "            f.size(lead_variant_stats) == 1,\n",
    "            lead_variant_stats.getItem(0).getField(\"posteriorProbability\"),\n",
    "        )\n",
    "        .otherwise(None)\n",
    "        .alias(\"posteriorProbability\")\n",
    "    )\n",
    "\n",
    "\n",
    "def create_maf_dataset(si: StudyIndex, cs: StudyLocus, vi: VariantIndex):\n",
    "    \"\"\"Create MAF dataset from StudyIndex, StudyLocus and VariantIndex.\n",
    "\n",
    "    Args:\n",
    "        si (StudyIndex): StudyIndex object\n",
    "        cs (StudyLocus): StudyLocus object\n",
    "        vi (VariantIndex): VariantIndex object\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: MAF dataset\n",
    "\n",
    "    \"\"\"\n",
    "    _cs = cs.df.select(\n",
    "        f.col(\"studyId\"),\n",
    "        f.col(\"studyLocusId\"),\n",
    "        f.col(\"variantId\"),\n",
    "        f.col(\"beta\"),\n",
    "        f.col(\"zScore\"),\n",
    "        f.col(\"pValueMantissa\"),\n",
    "        f.col(\"pValueExponent\"),\n",
    "        f.col(\"standardError\"),\n",
    "        f.col(\"finemappingMethod\"),\n",
    "        f.col(\"studyType\"),\n",
    "        f.size(\"locus\").alias(\"credibleSetSize\"),\n",
    "        f.col(\"isTransQtl\"),\n",
    "        extract_pip_from_locus(f.col(\"variantId\"), f.col(\"locus\")),\n",
    "    )\n",
    "    _si = si.df.select(\n",
    "        f.col(\"studyId\"),\n",
    "        f.col(\"nSamples\"),\n",
    "        f.col(\"nControls\"),\n",
    "        f.col(\"nCases\"),\n",
    "        f.col(\"geneId\"),  # for molqtl traits\n",
    "        f.col(\"traitFromSourceMappedIds\"),\n",
    "        major_population_in_study(f.col(\"ldPopulationStructure\"), \"nfe\").alias(\"majorPopulation\"),\n",
    "    )\n",
    "\n",
    "    _vi = vi.df.select(\n",
    "        f.col(\"variantId\"),\n",
    "        f.col(\"allelefrequencies\"),\n",
    "        vep_variant_effect(\"variantEffect\").alias(\"vepEffect\"),\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        _cs.join(_si, how=\"left\", on=\"studyId\")\n",
    "        .join(_vi, how=\"left\", on=\"variantId\")\n",
    "        .select(\n",
    "            \"*\",\n",
    "            major_population_allele_freq(\n",
    "                f.col(\"majorPopulation\"),\n",
    "                f.col(\"alleleFrequencies\"),\n",
    "            ).alias(\"majorPopulationAF\"),\n",
    "        )\n",
    "        .select(\n",
    "            \"*\",\n",
    "            maf(f.col(\"majorPopulationAf\")).alias(\"majorPopulationMAF\"),\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAF dataset consists of specific fields from credible sets, study index and variant index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_maf = create_maf_dataset(si, cs, vi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of lead variants is 2622098\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataset_maf.write.mode(\"overwrite\").parquet(\"../../data/lead-maf-vep\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
