{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify the input of functional genomics data in feature groups\n",
    "\n",
    "This notebook aims to create dataset combinations to quantify the feature groups input\n",
    "\n",
    "The following combinations are analysed:\n",
    "1. GWAS credible sets\n",
    "2. eQTL + GWAS\n",
    "3. eQTL + sceQTL + GWAS\n",
    "4. pQTL + GWAS\n",
    "5. tsQTL + GWAS\n",
    "\n",
    "Steps for the analysis\n",
    "\n",
    "* Build credible set from the conditional combinations\n",
    "* Build feature matrix for each combination\n",
    "* Run model training with default parameters\n",
    "* Run model predict with default paramters\n",
    "* Plot model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "from gentropy.common.session import Session\n",
    "from gentropy.dataset.study_locus import StudyLocus\n",
    "from gentropy.l2g import LocusToGeneFeatureMatrixStep, LocusToGeneStep\n",
    "from loguru import logger\n",
    "from pyspark.sql import functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/07 12:48:29 WARN Utils: Your hostname, mindos resolves to a loopback address: 127.0.1.1; using 192.168.0.100 instead (on interface eno1)\n",
      "25/04/07 12:48:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/07 12:48:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "session = Session(extended_spark_conf={\"spark.driver.memory\": \"60G\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "variant_index_path = \"../variant_effect_prediction/variant\"\n",
    "credible_set_path = \"../variant_effect_prediction/credible_set\"\n",
    "study_index_path = \"../variant_effect_prediction/study\"\n",
    "target_index_path = \"/home/mindos/data/ot-platform/2503-testrun-3/target\"\n",
    "colocalisation_path = \"/home/mindos/data/ot-platform/2503-testrun-3/colocalisation*\"\n",
    "gold_standard_path = \"/home/mindos/data/ot-platform/gold_standard.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [\n",
    "    # max CLPP for each (study, locus, gene) aggregating over a specific qtl type\n",
    "    \"eQtlColocClppMaximum\",\n",
    "    \"pQtlColocClppMaximum\",\n",
    "    \"sQtlColocClppMaximum\",\n",
    "    # max H4 for each (study, locus, gene) aggregating over a specific qtl type\n",
    "    \"eQtlColocH4Maximum\",\n",
    "    \"pQtlColocH4Maximum\",\n",
    "    \"sQtlColocH4Maximum\",\n",
    "    # max CLPP for each (study, locus, gene) aggregating over a specific qtl type and in relation with the mean in the vicinity\n",
    "    \"eQtlColocClppMaximumNeighbourhood\",\n",
    "    \"pQtlColocClppMaximumNeighbourhood\",\n",
    "    \"sQtlColocClppMaximumNeighbourhood\",\n",
    "    # max H4 for each (study, locus, gene) aggregating over a specific qtl type and in relation with the mean in the vicinity\n",
    "    \"eQtlColocH4MaximumNeighbourhood\",\n",
    "    \"pQtlColocH4MaximumNeighbourhood\",\n",
    "    \"sQtlColocH4MaximumNeighbourhood\",\n",
    "    # distance to gene footprint\n",
    "    \"distanceSentinelFootprint\",\n",
    "    \"distanceSentinelFootprintNeighbourhood\",\n",
    "    \"distanceFootprintMean\",\n",
    "    \"distanceFootprintMeanNeighbourhood\",\n",
    "    # distance to gene tss\n",
    "    \"distanceTssMean\",\n",
    "    \"distanceTssMeanNeighbourhood\",\n",
    "    \"distanceSentinelTss\",\n",
    "    \"distanceSentinelTssNeighbourhood\",\n",
    "    # vep\n",
    "    \"vepMaximum\",\n",
    "    \"vepMaximumNeighbourhood\",\n",
    "    \"vepMean\",\n",
    "    \"vepMeanNeighbourhood\",\n",
    "    # other\n",
    "    \"geneCount500kb\",\n",
    "    \"proteinGeneCount500kb\",\n",
    "    \"credibleSetConfidence\",\n",
    "]\n",
    "hyperparameters = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 3,\n",
    "    \"ccp_alpha\": 0,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"subsample\": 0.7,\n",
    "}\n",
    "l2g_threshold = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.100:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>gentropy</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x789f72e09e50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class L2GParamSet:\n",
    "    run_id: str\n",
    "    variant_index_path: str\n",
    "    colocalisation_path: str\n",
    "    study_index_path: str\n",
    "    target_index_path: str\n",
    "    credible_set_path: str\n",
    "    gold_standard_path: str\n",
    "    l2g_threshold: float\n",
    "    explain_predictions: bool\n",
    "    study_types: tuple[Literal[\"gwas\", \"pqtl\", \"sqtl\", \"eqtl\", \"tuqtl\", \"sceqtl\"]]\n",
    "    temp_path: str = \".\"\n",
    "\n",
    "    def to_params(self) -> dict[str, str]:\n",
    "        \"\"\"Convert paramters to dictionary.\"\"\"\n",
    "        return {\n",
    "            \"run_id\": self.run_id,\n",
    "            \"variant_index_path\": self.variant_index_path,\n",
    "            \"colocalisation_path\": self.colocalisation_path,\n",
    "            \"study_index_path\": self.study_index_path,\n",
    "            \"target_index_path\": self.target_index_path,\n",
    "            \"credible_set_path\": self.limit_cs(self.credible_set_path, self.study_types),\n",
    "            \"feature_matrix_path\": str(Path(self.temp_path) / \"feature_matrix\" / self.run_id + \"_feature_matrix\"),\n",
    "            \"model_path\": str(Path(self.temp_path) / \"l2g_model\" / self.run_id + \"_l2g_model.skops\"),\n",
    "            \"gold_standard_path\": self.gold_standard_path,\n",
    "            \"l2g_threshold\": self.l2g_threshold,\n",
    "            \"predictions_path\": str(Path(self.temp_path) / \"l2g_predictions\" / self.run_id + \"_l2g_predictions\"),\n",
    "            \"explain_predictions\": self.explain_predictions,\n",
    "        }\n",
    "\n",
    "    def limit_cs(self) -> str:\n",
    "        \"\"\"Limit credible sets to specific number of study types, dump it and use for to_params method.\"\"\"\n",
    "        cs = StudyLocus.from_parquet(session, self.credible_set_path).df.filter(\n",
    "            f.col(\"studyType\").isin(self.study_types)\n",
    "        )\n",
    "        cs_path = str(Path(self.temp_path / \"credible_set\" / self.run_id + \"_credible_set\"))\n",
    "        cs.write.mode(\"overwrite\").parquet(cs_path)\n",
    "        return cs_path\n",
    "\n",
    "\n",
    "runs = {\n",
    "    \"gwas_only\": [\"gwas\"],\n",
    "    \"gwas_vs_bulk_eqtl\": [\"gwas\", \"eqtl\"],\n",
    "    \"gwas_vs_sceqtl\": [\"gwas\", \"sceqtl\"],\n",
    "    \"gwas_vs_eqtl\": [\"gwas\", \"eqtl\", \"sceqtl\"],\n",
    "    \"gwas_vs_pqtl\": [\"gwas\", \"pqtl\"],\n",
    "    \"gwas_vs_tuqtl\": [\"gwas\", \"tuqtl\"],\n",
    "    \"gwas_vs_sqtl\": [\"gwas\", \"sqtl\"],\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    run_id: {\n",
    "        L2GParamSet(\n",
    "            run_id=run_id,\n",
    "            variant_index_path=variant_index_path,\n",
    "            colocalisation_path=colocalisation_path,\n",
    "            study_index_path=study_index_path,\n",
    "            target_index_path=target_index_path,\n",
    "            credible_set_path=credible_set_path,\n",
    "            gold_standard_path=gold_standard_path,\n",
    "            explain_predictions=True,\n",
    "            l2g_threshold=l2g_threshold,\n",
    "            study_types=study_types,\n",
    "        ).to_params()\n",
    "    }\n",
    "    for run_id, study_types in runs.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combination, params in param_grid:\n",
    "    logger.info(f\"Running combination {combination}\")\n",
    "\n",
    "    logger.info(\"Building feature matrix\")\n",
    "    LocusToGeneFeatureMatrixStep(\n",
    "        session,\n",
    "        features_list=features_list,\n",
    "        credible_set_path=combination,\n",
    "        variant_index_path=params[\"variant_index_path\"],\n",
    "        colocalisation_path=params[\"colocalisation_path\"],\n",
    "        study_index_path=params[\"study_index_path\"],\n",
    "        target_index_path=params[\"target_index_path\"],\n",
    "        feature_matrix_path=params[\"feature_matrix_path\"],\n",
    "    )\n",
    "\n",
    "    logger.info(\"Running training\")\n",
    "    LocusToGeneStep(\n",
    "        session,\n",
    "        run_mode=\"train\",\n",
    "        hyperparameters=hyperparameters,\n",
    "        download_from_hub=False,\n",
    "        cross_validate=False,\n",
    "        wandb_run_Name=f\"2504-gentropy-manuscript-{combination}\",\n",
    "        credible_set_path=params[\"credible_set_path\"],\n",
    "        feature_matrix_path=params[\"feature_matrix_path\"],\n",
    "        model_path=params[\"model_path\"],\n",
    "        features_list=features_list,\n",
    "        gold_standard_curation_path=params[\"gold_standard_path\"],\n",
    "        l2g_threshold=params[\"l2g_threshold\"],\n",
    "        hf_hub_repo_id=None,\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Running predictions\")\n",
    "    LocusToGeneStep(\n",
    "        session,\n",
    "        run_mode=\"predict\",\n",
    "        hyperparameters=hyperparameters,\n",
    "        download_from_hub=False,\n",
    "        cross_validate=True,\n",
    "        wandb_run_Name=f\"2504-gentropy-manuscript-{combination}\",\n",
    "        credible_set_path=params[\"credible_set_path\"],\n",
    "        feature_matrix_path=params[\"feature_matrix_path\"],\n",
    "        model_path=params[\"model_path\"],\n",
    "        features_list=features_list,\n",
    "        gold_standard_curation_path=params[\"gold_standard_path\"],\n",
    "        variant_index_path=params[\"variant_index_path\"],\n",
    "        predictions_path=params[\"predictions_path\"],\n",
    "        l2g_threshold=params[\"l2g_threshold\"],\n",
    "        explain_predictions=params[\"explain_predictions\"],\n",
    "        hf_hub_repo_id=None,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
